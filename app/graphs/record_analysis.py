from typing import TypedDict, List, Dict, Any, Optional, Annotated
from operator import add
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.postgres import PostgresSaver
from google import genai
from google.genai import types
from config import settings
from app.database import get_langgraph_connection_string
import logging
import json
from datetime import datetime

logger = logging.getLogger(__name__)


# ==================== Pydantic ëª¨ë¸ ====================

class GeneratedQuestion(BaseModel):
    """ìƒì„±ëœ ì§ˆë¬¸ ëª¨ë¸"""
    category: str = Field(description="ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬")
    content: str = Field(description="ì§ˆë¬¸ ë‚´ìš©")
    difficulty: str = Field(description="ë‚œì´ë„ (ê¸°ë³¸, ì‹¬í™”, ì••ë°•)")
    purpose: str = Field(description="ì§ˆë¬¸ì˜ ëª©ì ")
    answer_points: str = Field(description="ë‹µë³€ í¬ì¸íŠ¸")
    model_answer: str = Field(description="ëª¨ë²” ë‹µì•ˆ")
    evaluation_criteria: str = Field(description="í‰ê°€ ê¸°ì¤€")


class QuestionListResponse(BaseModel):
    """ì§ˆë¬¸ ëª©ë¡ ì‘ë‹µ ëª¨ë¸"""
    questions: List[GeneratedQuestion]


# ==================== State ====================

class QuestionGenerationState(TypedDict):
    """ì§ˆë¬¸ ìƒì„± ìƒíƒœ - Annotated ë°©ì‹ìœ¼ë¡œ Reducer ì‚¬ìš©"""
    
    # ê³ ì • ê°’ (ë®ì–´ì“°ê¸°)
    record_id: int
    target_school: str
    target_major: str
    interview_type: str
    
    # ëˆ„ì  ê°’ (ì¶”ê°€ - reducer ì‚¬ìš©)
    processed_categories: Annotated[List[str], add]
    all_questions: Annotated[List[Dict[str, Any]], add]
    failed_categories: Annotated[List[str], add]  # ì‹¤íŒ¨í•œ ì¹´í…Œê³ ë¦¬ ì¶”ì 
    
    # ë‹¨ì¼ ê°’ (ë®ì–´ì“°ê¸°)
    current_category: Optional[str]
    progress: int
    status_message: str
    error: str


class QuestionGenerationGraph:
    """ë²Œí¬ ì§ˆë¬¸ ìƒì„± ê·¸ë˜í”„ (SSE ìŠ¤íŠ¸ë¦¬ë° ì§€ì›)"""

    # ì¹´í…Œê³ ë¦¬ ì •ì˜
    CATEGORIES = ["ì„±ì ", "ì„¸íŠ¹", "ì°½ì²´", "í–‰íŠ¹", "ê¸°íƒ€"]

    def __init__(self):
        # PostgreSQL Checkpointer ì´ˆê¸°í™”
        try:
            from langgraph.checkpoint.memory import InMemorySaver
            
            connection_string = get_langgraph_connection_string()
            
            # PostgresSaverëŠ” ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ì´ë¯€ë¡œ ì§„ì…ì´ í•„ìš”í•¨
            # ê°„ë‹¨í•œ InMemorySaverë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, PostgreSQLì´ í•„ìš”í•œ ê²½ìš° ë³„ë„ ì´ˆê¸°í™” í•„ìš”
            # í˜„ì¬ë¡œì„œëŠ” ì•ˆì •ì„±ì„ ìœ„í•´ InMemorySaver ì‚¬ìš©
            self.checkpointer = InMemorySaver()
            logger.info("LangGraph InMemory Checkpointer initialized successfully")
            
            # TODO: ì¶”í›„ PostgreSQL ì²´í¬í¬ì¸í„°ê°€ í•„ìš”í•œ ê²½ìš° ì•„ë˜ íŒ¨í„´ ì‚¬ìš©
            # async with PostgresSaver.from_conn_string(connection_string) as checkpointer:
            #     self.checkpointer = checkpointer
        except Exception as e:
            logger.error(f"Failed to initialize checkpointer: {e}")
            from langgraph.checkpoint.memory import InMemorySaver
            self.checkpointer = InMemorySaver()

        # Google GenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = genai.Client(api_key=settings.google_api_key)
        self.model = "gemini-2.5-flash-lite"
        self.types = types

        # ê·¸ë˜í”„ ë¹Œë“œ
        self.graph = self._build_graph()

    def _build_graph(self) -> StateGraph:
        """LangGraph ë¹Œë“œ"""
        workflow = StateGraph(QuestionGenerationState)

        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("initialize", self.initialize)
        workflow.add_node("process_category", self.process_category)
        workflow.add_node("finalize", self.finalize)

        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("initialize")
        workflow.add_edge("initialize", "process_category")
        workflow.add_conditional_edges(
            "process_category",
            self.should_continue,
            {
                "continue": "process_category",
                "end": "finalize"
            }
        )
        workflow.add_edge("finalize", END)

        # Checkpointerì™€ í•¨ê»˜ ì»´íŒŒì¼
        return workflow.compile(checkpointer=self.checkpointer)

    async def initialize(self, state: QuestionGenerationState) -> QuestionGenerationState:
        """ì´ˆê¸°í™”"""
        logger.info(f"Initializing question generation for record {state['record_id']}")

        state['processed_categories'] = []
        state['all_questions'] = []
        state['failed_categories'] = []
        state['current_category'] = self.CATEGORIES[0]
        state['progress'] = 5
        state['status_message'] = "ì§ˆë¬¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤"
        state['error'] = None

        return state

    async def process_category(self, state: QuestionGenerationState) -> QuestionGenerationState:
        """ì¹´í…Œê³ ë¦¬ë³„ ì§ˆë¬¸ ìƒì„± (ë‚´ë¶€ ì¬ì‹œë„ ë¡œì§, SSEì— ë…¸ì¶œë˜ì§€ ì•ŠìŒ)"""
        current_category = state['current_category']
        max_retries = 2  # ìµœëŒ€ 2íšŒ ì¬ì‹œë„ (ì´ 3íšŒ ì‹œë„)
        
        logger.info(f"ğŸ”„ Processing category: {current_category}")

        try:
            # 1. ë²¡í„° DBì—ì„œ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì²­í¬ ê²€ìƒ‰
            relevant_chunks = await self._retrieve_relevant_chunks(
                state['record_id'],
                current_category
            )

            if not relevant_chunks:
                # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                logger.warning(f"âš ï¸ No chunks found for category: {current_category}, skipping...")
                
                num_processed = len(state['processed_categories'])
                progress = int(((num_processed + 1) / len(self.CATEGORIES)) * 90)
                remaining_categories = [cat for cat in self.CATEGORIES if cat not in state['processed_categories'] + [current_category]]
                
                return {
                    "processed_categories": [current_category],
                    "current_category": remaining_categories[0] if remaining_categories else None,
                    "progress": progress,
                    "status_message": f"{current_category} ì˜ì—­ ë°ì´í„° ì—†ìŒ, ë‹¤ìŒ ì˜ì—­ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤...",
                    "error": None
                }
            
            # 2. ë‚´ë¶€ ì¬ì‹œë„ ë£¨í”„ (ìµœëŒ€ 3íšŒ ì‹œë„: ì´ˆê¸° 1íšŒ + ì¬ì‹œë„ 2íšŒ)
            last_error = None
            questions = []
            
            for attempt in range(max_retries + 1):  # 0, 1, 2
                try:
                    logger.info(f"  ğŸ“ Attempt {attempt + 1}/{max_retries + 1} for {current_category}")
                    
                    # ì§ˆë¬¸ ìƒì„±
                    questions = await self._generate_questions_for_category(
                        category=current_category,
                        chunks=relevant_chunks,
                        target_school=state['target_school'],
                        target_major=state['target_major'],
                        interview_type=state['interview_type']
                    )

                    # ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ ì²´í¬
                    if not questions:
                        raise ValueError(f"{current_category} ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ (ë¹ˆ ì‘ë‹µ)")

                    # âœ… ì„±ê³µ: ë£¨í”„ ì¢…ë£Œ
                    logger.info(f"  âœ… Successfully generated {len(questions)} questions for {current_category} (attempt {attempt + 1})")
                    break
                    
                except Exception as e:
                    last_error = e
                    logger.warning(f"  âŒ Attempt {attempt + 1} failed for {current_category}: {e}")
                    
                    if attempt < max_retries:
                        # ì¬ì‹œë„ ëŒ€ê¸° (1ì´ˆ)
                        import asyncio
                        await asyncio.sleep(1)
                        logger.info(f"  ğŸ”„ Retrying {current_category}...")
                    else:
                        # ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼: ì—ëŸ¬ ë˜ì§
                        logger.error(f"  âŒ All {max_retries + 1} attempts failed for {current_category}")
                        raise Exception(f"{current_category} ì¹´í…Œê³ ë¦¬ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ (ìµœëŒ€ {max_retries + 1}íšŒ ì‹œë„): {str(e)}")

            # 3. ì„±ê³µ: ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ì´ë™
            num_processed = len(state['processed_categories'])
            progress = int(((num_processed + 1) / len(self.CATEGORIES)) * 90)
            remaining_categories = [cat for cat in self.CATEGORIES if cat not in state['processed_categories'] + [current_category]]
            
            return {
                "all_questions": questions,
                "processed_categories": [current_category],
                "current_category": remaining_categories[0] if remaining_categories else None,
                "progress": progress,
                "status_message": f"{current_category} ì˜ì—­ ë¶„ì„ ì™„ë£Œ...",
                "error": None
            }

        except Exception as e:
            # ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼: í•´ë‹¹ ì¹´í…Œê³ ë¦¬ë§Œ ìŠ¤í‚µí•˜ê³  ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ê³„ì†
            logger.error(f"âŒ Failed to generate questions for {current_category} after 3 attempts: {e}")
            logger.info(f"â­ï¸ Skipping {current_category} and continuing to next category...")
            
            num_processed = len(state['processed_categories'])
            progress = int(((num_processed + 1) / len(self.CATEGORIES)) * 90)
            remaining_categories = [cat for cat in self.CATEGORIES if cat not in state['processed_categories'] + [current_category]]
            
            return {
                "processed_categories": [current_category],  # ì²˜ë¦¬ëœ ê²ƒìœ¼ë¡œ í‘œì‹œ
                "failed_categories": [current_category],     # ì‹¤íŒ¨ ëª©ë¡ì— ì¶”ê°€
                "current_category": remaining_categories[0] if remaining_categories else None,
                "progress": progress,
                "status_message": f"{current_category} ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ë¡œ ê±´ë„ˆëœë‹ˆë‹¤...",
                "error": None  # ì¹˜ëª…ì  ì—ëŸ¬ê°€ ì•„ë‹ˆë¯€ë¡œ error í•„ë“œëŠ” None
            }

    async def finalize(self, state: QuestionGenerationState) -> QuestionGenerationState:
        """ë§ˆë¬´ë¦¬"""
        failed_cats = state.get('failed_categories', [])
        total_questions = len(state['all_questions'])
        
        if failed_cats:
            logger.warning(f"âš ï¸ Failed categories: {failed_cats}")
            state['status_message'] = f"ì§ˆë¬¸ ìƒì„± ì™„ë£Œ! ì´ {total_questions}ê°œ ì§ˆë¬¸ ìƒì„±. {len(failed_cats)}ê°œ ì¹´í…Œê³ ë¦¬({', '.join(failed_cats)}) ì‹¤íŒ¨ë¡œ ê±´ë„ˆëœ€."
        else:
            logger.info(f"âœ… All categories succeeded. Total questions: {total_questions}")
            state['status_message'] = f"ì§ˆë¬¸ ìƒì„± ì™„ë£Œ! ì´ {total_questions}ê°œ ì§ˆë¬¸ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."

        state['progress'] = 100
        state['current_category'] = None

        return state

    async def _retrieve_relevant_chunks(
        self,
        record_id: int,
        category: str
    ) -> List[Dict[str, Any]]:
        """
        ë²¡í„° DBì—ì„œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
        """
        from app.models import RecordChunk
        from app.database import get_db
        
        try:
            # DB ì„¸ì…˜ ìƒì„±
            db_generator = get_db()
            db = next(db_generator)
            
            try:
                # ì¹´í…Œê³ ë¦¬ë³„ ì²­í¬ ì¡°íšŒ (record_idì™€ categoryë¡œ í•„í„°ë§)
                chunks = db.query(RecordChunk).filter(
                    RecordChunk.record_id == record_id,
                    RecordChunk.category == category
                ).order_by(RecordChunk.chunk_index).all()
                
                # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
                result = [
                    {
                        "text": chunk.chunk_text,
                        "category": chunk.category
                    }
                    for chunk in chunks
                ]
                
                logger.info(f"Retrieved {len(result)} chunks for category {category}")
                return result
                
            finally:
                db.close()
                
        except Exception as e:
            logger.error(f"Error retrieving chunks for category {category}: {e}")
            return []

    async def _generate_questions_for_category(
        self,
        category: str,
        chunks: List[Dict[str, Any]],
        target_school: str,
        target_major: str,
        interview_type: str
    ) -> List[Dict[str, Any]]:
        """
        ì¹´í…Œê³ ë¦¬ë³„ ì§ˆë¬¸ ìƒì„± (google.genai ì‚¬ìš©)
        """
        try:
            # ì²­í¬ í…ìŠ¤íŠ¸ ê²°í•© (ëª¨ë“  ì²­í¬ ì‚¬ìš©)
            logger.info(f"Generating questions for {category}: using all {len(chunks)} chunks")
            context = "\n\n".join([chunk['text'] for chunk in chunks])

            # í”„ë¡¬í”„íŠ¸ (ì‹œìŠ¤í…œ + ì‚¬ìš©ì ê²°í•©)
            prompt = f"""ë‹¹ì‹ ì€ ëŒ€í•™ ì…ì‹œ ë©´ì ‘ ì¤€ë¹„ë¥¼ ìœ„í•œ AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤.

í•™ìƒì˜ ìƒí™œê¸°ë¡ë¶€ {category} ê´€ë ¨ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ì˜ˆìƒ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ëª©í‘œ í•™êµ**: {target_school}
**ëª©í‘œ ì „ê³µ**: {target_major}
**ì „í˜• ìœ í˜•**: {interview_type}

**ì§€ì¹¨**:
1. {category} ì˜ì—­ì—ì„œ í•µì‹¬ì ì¸ ì§ˆë¬¸ 3~5ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.
2. ì§ˆë¬¸ì€ êµ¬ì²´ì ì´ê³  ëª…í™•í•´ì•¼ í•©ë‹ˆë‹¤.
3. ê° ì§ˆë¬¸ì— ëŒ€í•´ ì§ˆë¬¸ ëª©ì , ëª¨ë²” ë‹µì•ˆ, ë‹µë³€ í¬ì¸íŠ¸, í‰ê°€ ê¸°ì¤€ì„ ì œì‹œí•˜ì„¸ìš”.
4. purpose ì˜ˆì‹œ : í•™ìƒì˜ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ í‰ê°€, í˜‘ë™ì‹¬ í‰ê°€ ë“±
5. answer_points ì˜ˆì‹œ : ìë£Œ ì¡°ì‚¬, ê²½í—˜ ì‚¬ë¡€ ì œì‹œ ë“±
6. model_answerëŠ” ì‹¤ì œ ë‹µì•ˆì²˜ëŸ¼ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ë„ ì¢‹ìŠµë‹ˆë‹¤.
7. evaluation_criteria ì˜ˆì‹œ: STAR ê¸°ë²• í™œìš©, ëª¨ë²” ë‹µì•ˆì—ì„œ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¥¼ ì œì‹œí•¨ ë“±

**ë‚œì´ë„ êµ¬ë¶„**:
- ê¸°ë³¸: ê¸°ë³¸ì ì¸ ì§ˆë¬¸
- ì‹¬í™”: ê¹Šì´ ìˆëŠ” ì§ˆë¬¸
- ì••ë°•: ì••ë°•ê° ìˆëŠ” ì§ˆë¬¸

ë‹¤ìŒì€ í•™ìƒ ìƒí™œê¸°ë¡ë¶€ì˜ {category} ê´€ë ¨ ë‚´ìš©ì…ë‹ˆë‹¤:

{context}

ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìœ„ì˜ ì§€ì¹¨ì— ë”°ë¼ ì˜ˆìƒ ë©´ì ‘ ì§ˆë¬¸ì„ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”."""

            # JSON ìŠ¤í‚¤ë§ˆ ì •ì˜
            schema = self.types.Schema(
                type=self.types.Type.OBJECT,
                properties={
                    "questions": self.types.Schema(
                        type=self.types.Type.ARRAY,
                        items=self.types.Schema(
                            type=self.types.Type.OBJECT,
                            properties={
                                "category": self.types.Schema(type=self.types.Type.STRING, description="ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬"),
                                "content": self.types.Schema(type=self.types.Type.STRING, description="ì§ˆë¬¸ ë‚´ìš©"),
                                "difficulty": self.types.Schema(type=self.types.Type.STRING, description="ë‚œì´ë„ (ê¸°ë³¸, ì‹¬í™”, ì••ë°•)"),
                                "purpose": self.types.Schema(type=self.types.Type.STRING, description="ì§ˆë¬¸ì˜ ëª©ì "),
                                "answer_points": self.types.Schema(type=self.types.Type.STRING, description="ë‹µë³€ í¬ì¸íŠ¸"),
                                "model_answer": self.types.Schema(type=self.types.Type.STRING, description="ëª¨ë²” ë‹µì•ˆ"),
                                "evaluation_criteria": self.types.Schema(type=self.types.Type.STRING, description="í‰ê°€ ê¸°ì¤€"),
                            },
                            required=["category", "content", "difficulty", "purpose", "answer_points", "model_answer", "evaluation_criteria"]
                        )
                    )
                },
                required=["questions"]
            )

            # Google GenAIë¡œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ìƒì„±
            response = self.client.models.generate_content(
                model=self.model,
                contents=prompt,
                config=self.types.GenerateContentConfig(
                    response_mime_type="application/json",
                    response_schema=schema,
                    temperature=0.7
                )
            )

            # JSON íŒŒì‹±
            result = json.loads(response.text)
            questions = result.get("questions", [])

            logger.info(f"Generated {len(questions)} questions for {category}")
            return questions

        except Exception as e:
            logger.error(f"Error generating questions for {category}: {e}")
            return []

    def should_continue(self, state: QuestionGenerationState) -> str:
        """ê³„ì† ì§„í–‰ ì—¬ë¶€ íŒë‹¨"""
        # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ
        if state.get('error'):
            return "end"

        # ë‚¨ì€ ì¹´í…Œê³ ë¦¬ í™•ì¸
        remaining = [cat for cat in self.CATEGORIES if cat not in state.get('processed_categories', [])]
        if remaining:
            return "continue"

        return "end"

    async def astream(self, state: QuestionGenerationState):
        """
        ë¹„ë™ê¸° ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰ (SSEìš©)
        """
        async for event in self.graph.astream(state):
            # ê° ë…¸ë“œ ì‹¤í–‰ í›„ ìƒíƒœë¥¼ yield
            for node_name, node_state in event.items():
                yield node_state


question_generation_graph = QuestionGenerationGraph()
