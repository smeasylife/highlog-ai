"""PDF ë²¡í„°í™” ì„œë¹„ìŠ¤ - Gemini ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ë³„ ì²­í‚¹ & Embedding"""
import logging
from typing import List, Dict, Tuple
from app.models import RecordChunk
from sqlalchemy.orm import Session

logger = logging.getLogger(__name__)


class VectorService:
    """PDF ë²¡í„°í™” ì„œë¹„ìŠ¤ - Gemini ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ë³„ ì²­í‚¹ & Embedding"""
    
    def __init__(self):
        # google.genai í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        from google import genai
        from google.genai import types
        from config import settings
        
        self.client = genai.Client(api_key=settings.google_api_key)
        self.types = types
        self.embedding_model = 'text-multilingual-embedding-002'
        self.chat_model = 'gemini-2.5-flash-lite'  # ì²­í‚¹ìš© ëª¨ë¸
    
    async def vectorize_pdf(
        self,
        pdf_images,
        record_id: int,
        db: Session
    ) -> Tuple[bool, str]:
        """
        PDF ì´ë¯¸ì§€ë¥¼ Geminië¡œ ì²­í‚¹í•˜ê³  ë²¡í„°í™”í•˜ì—¬ DB ì €ì¥
        
        Args:
            pdf_images: PIL ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            record_id: ìƒê¸°ë¶€ ID
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            
        Returns:
            (ì„±ê³µ ì—¬ë¶€, ë©”ì‹œì§€)
        """
        try:
            logger.info(f"Starting Gemini-based vectorization for record {record_id}")
            
            # 1. ì´ë¯¸ì§€ë¥¼ 8ì¥ì”© ë°°ì¹˜ë¡œ ë¶„í• 
            batch_size = 8
            batches = [pdf_images[i:i + batch_size] for i in range(0, len(pdf_images), batch_size)]
            logger.info(f"Split {len(pdf_images)} pages into {len(batches)} batches")
            
            # 2. ê° ë°°ì¹˜ë¥¼ Geminië¡œ íŒŒì‹±
            all_chunks = []
            for i, batch in enumerate(batches):
                try:
                    chunks = await self._parse_batch_with_gemini(batch, i, len(batches))
                    all_chunks.extend(chunks)
                    logger.info(f"Batch {i+1}/{len(batches)} parsed: {len(chunks)} chunks")
                except Exception as e:
                    logger.error(f"Error parsing batch {i+1}: {e}")
                    continue
            
            if not all_chunks:
                return False, "ì²­í¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            logger.info(f"Total chunks extracted: {len(all_chunks)}")
            
            # 3. ê° ì²­í¬ë¥¼ ë²¡í„°í™”í•˜ê³  ì €ì¥
            saved_count = 0
            for chunk_data in all_chunks:
                try:
                    # í…ìŠ¤íŠ¸ ì„ë² ë”©
                    embedding = await self._embed_text(chunk_data['text'])
                    
                    # DB ì €ì¥
                    chunk = RecordChunk(
                        record_id=record_id,
                        chunk_text=chunk_data['text'],
                        chunk_index=chunk_data['index'],
                        category=chunk_data['category'],
                        embedding=str(embedding)
                    )
                    db.add(chunk)
                    saved_count += 1
                    
                except Exception as e:
                    logger.error(f"Error processing chunk {chunk_data['index']}: {e}")
                    continue
            
            db.commit()
            logger.info(f"Successfully saved {saved_count} chunks for record {record_id}")
            
            return True, f"{saved_count}ê°œ ì²­í¬ê°€ ë²¡í„°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."
            
        except Exception as e:
            logger.error(f"Error vectorizing PDF: {e}")
            db.rollback()
            return False, f"ë²¡í„°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    async def _parse_batch_with_gemini(
        self,
        batch_images,
        batch_index: int,
        total_batches: int
    ) -> List[Dict]:
        """
        Gemini 2.5 Flash-Liteë¡œ ì´ë¯¸ì§€ ë°°ì¹˜ë¥¼ íŒŒì‹±
        
        Args:
            batch_images: PIL ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            batch_index: ë°°ì¹˜ ì¸ë±ìŠ¤
            total_batches: ì „ì²´ ë°°ì¹˜ ìˆ˜
            
        Returns:
            ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        import json
        import io
        from PIL import Image
        
        logger.info(f"Parsing batch {batch_index + 1}/{total_batches} with Gemini...")
        
        prompt = """ë‹¹ì‹ ì€ í•™êµ ìƒí™œê¸°ë¡ë¶€ ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤.

ì´ ì´ë¯¸ì§€ë“¤ì€ í•™ìƒì˜ ìƒí™œê¸°ë¡ë¶€ PDF í˜ì´ì§€ë“¤ì…ë‹ˆë‹¤. ê° í˜ì´ì§€ì˜ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ **ì¹´í…Œê³ ë¦¬ë³„ë¡œ ì²­í‚¹**í•˜ê³  **JSON í˜•ì‹**ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.

## ğŸ“‹ ì²­í‚¹ ê·œì¹™

0. **ğŸš¨ ì •í™•ì„± ì›ì¹™ (ê°€ì¥ ì¤‘ìš”)** - **Hallucination ê¸ˆì§€**:
   - **ì´ë¯¸ì§€ì— ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ ìˆëŠ” ê·¸ëŒ€ë¡œ ì¶”ì¶œí•˜ì„¸ìš”** - ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
   - í…ìŠ¤íŠ¸ì˜ **ë„ì–´ì“°ê¸°, ë¬¸ì¥ ë¶€í˜¸, ì¤„ë°”ê¿ˆì„ ê·¸ëŒ€ë¡œ ìœ ì§€**í•˜ì„¸ìš”
   - **ë‚´ìš©ì„ ì¶”ê°€, ìš”ì•½, paraphraseí•˜ì§€ ë§ˆì„¸ìš”** - ì›ë¬¸ ê·¸ëŒ€ë¡œë§Œ ì¶”ì¶œ
   - ë¶ˆë¶„ëª…í•˜ê±°ë‚˜ ì˜ë¦° í…ìŠ¤íŠ¸ëŠ” **[ì¼ë¶€ í…ìŠ¤íŠ¸ ëˆ„ë½]**ìœ¼ë¡œ í‘œì‹œí•˜ê³  ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”
   - í‘œì˜ ìˆ«ì, ë‚ ì§œ, ì ìˆ˜ ë“± **ëª¨ë“  ë°ì´í„°ë¥¼ ì •í™•í•˜ê²Œ ê·¸ëŒ€ë¡œ ë³µì‚¬**í•˜ì„¸ìš”
   - OCR ê²°ê³¼ê°€ ë¶ˆí™•ì‹¤í•´ë„ **ì›ë¬¸ í˜•íƒœë¥¼ ìµœëŒ€í•œ ìœ ì§€**í•˜ì„¸ìš”
   - ë¬¸ë§¥ì„ ìƒìƒí•˜ê±°ë‚˜ ë‚´ìš©ì„ ë³´ì¶©í•˜ì§€ **ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”**

1. **ê°œì¸ì •ë³´ ì‚­ì œ**: ì´ë¦„, ìƒë…„ì›”ì¼, ì£¼ì†Œ, ì „í™”ë²ˆí˜¸ ë“± ê°œì¸ ì‹ë³„ ì •ë³´ëŠ” **ëª¨ë‘ ì‚­ì œ**í•˜ì„¸ìš”

2. **ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜**: ë‹¤ìŒ 5ê°œ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë¶„ë¥˜
   - **ì„±ì **: í•™ì—… ì„±ì·¨, ê³¼ëª© ì´ìˆ˜, ë‹¨ìœ„ìˆ˜, ì›ì ìˆ˜, í‘œì¤€ì ìˆ˜ ë“±
   - **ì„¸íŠ¹**: ì„¸ë¶€ëŠ¥ë ¥ ë° ì†Œê°œ, êµê³¼ ì£¼ì œ, íƒêµ¬ í™œë™ ë“±
   - **ì°½ì²´**: ì°½ì˜ì ì²´í—˜í™œë™, ë™ì•„ë¦¬, ë´‰ì‚¬, ì²´í—˜í™œë™ ë“±
   - **í–‰íŠ¹**: í–‰ë™íŠ¹ì„±, íƒœë„, í’ˆí–‰, í˜‘ë™, ì±…ì„ ë“±
   - **ê¸°íƒ€**: ë…ì„œ í™œë™, ì§„ë¡œ í™œë™, í¬ë§ì‚¬í•­, ì¶œê²° ìƒí™©, ìˆ˜ìƒ ê²½ë ¥ ë“± ê·¸ ì™¸ ëª¨ë“  ë‚´ìš©

3. **ì²­í¬ í¬ê¸°**: ê° ì²­í¬ëŠ” **500~1000ì** ì‚¬ì´
   - 1000ìë¥¼ ë„˜ìœ¼ë©´ ë‹¤ìŒ ì²­í¬ë¡œ ë¶„í• 
   - ì£¼ì œê°€ ë°”ë€Œë©´ 500ì ë¯¸ë§Œì´ë¼ë„ ë¶„í• 

4. **í‘œ ë°ì´í„°**: í‘œëŠ” **ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹**ìœ¼ë¡œ ë³€í™˜
   - **í‘œì˜ ëª¨ë“  ì…€ ë‚´ìš©ì„ ì •í™•í•˜ê²Œ ê·¸ëŒ€ë¡œ ë³µì‚¬** - ìš”ì•½í•˜ì§€ ë§ˆì„¸ìš”
   - ì—¬ëŸ¬ í˜ì´ì§€ì— ê±¸ì¹œ í‘œëŠ” í•˜ë‚˜ë¡œ ë³‘í•©

## ğŸ¯ ì¶œë ¥ í˜•ì‹

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ë°˜í™˜:

```json
{
  "records": [
    {
      "category": "ì„±ì ",
      "content": "| í•™ë…„ | ê³¼ëª© | ë‹¨ìœ„ | ì›ì ìˆ˜ | í‘œì¤€ì ìˆ˜ |\\\\n|------|------|------|--------|----------|\\\\n| 2í•™ë…„ | êµ­ì–´ | 5 | 85 | 78 |"
    },
    {
      "category": "ì„¸íŠ¹",
      "content": "### êµ­ì–´ê³¼\\\\n**ì£¼ì œ**: í•œêµ­ í˜„ëŒ€ ì†Œì„¤ì˜ ì„œì‚¬ êµ¬ì¡° ì—°êµ¬\\\\n**í™œë™ ë‚´ìš©**: ê¹€ë™ì¸ì˜ 'ìš´ìˆ˜ ì¢‹ì€ ë‚ 'ì„ ë¶„ì„í•˜ë©°..."
    }
  ]
}
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

- **ğŸš¨ ì ˆëŒ€ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš” - ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ë‚´ìš©ë§Œ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”**
- **ìš”ì•½, paraphrase, ë‚´ìš© ë³´ì¶©ì„ ì¼ì ˆ í•˜ì§€ ë§ˆì„¸ìš” - ì›ë¬¸ ê·¸ëŒ€ë¡œë§Œ ë³µì‚¬í•˜ì„¸ìš”**
- JSON ì™¸ì˜ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”
- ê°œì¸ì •ë³´ëŠ” ëª¨ë‘ ì‚­ì œí•˜ì„¸ìš”
- í‘œì˜ ë°ì´í„°ëŠ” ì†ì‹¤ ì—†ì´ ì •í™•í•˜ê²Œ ë³€í™˜í•˜ì„¸ìš”
- ì²­í¬ì˜ content í•„ë“œëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì„ ìœ ì§€í•˜ì„¸ìš”

ì´ì œ ìƒí™œê¸°ë¡ë¶€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."""
        
        try:
            # PIL ì´ë¯¸ì§€ë¥¼ genai.Partë¡œ ë³€í™˜
            image_parts = [self._pil_image_to_part(img) for img in batch_images]
            
            # Gemini 2.5 Flash-Liteì— ìš”ì²­ ì „ì†¡ (JSON ê°•ì œ)
            response = self.client.models.generate_content(
                model=self.chat_model,
                contents=[prompt] + image_parts,
                config=self.types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            
            # ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° JSON íŒŒì‹±
            response_text = response.text
            result = json.loads(response_text)
            
            records = result.get('records', [])
            logger.info(f"Gemini returned {len(records)} chunks")
            
            # RecordChunk í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            chunks = []
            for i, record in enumerate(records):
                chunks.append({
                    'index': i,
                    'text': record['content'],
                    'category': record['category']
                })
            
            return chunks
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON parsing failed: {e}")
            logger.error(f"Response text: {response_text[:1000]}")
            raise
        except Exception as e:
            logger.error(f"Gemini processing error: {e}")
            raise
    
    def _pil_image_to_part(self, image):
        """PIL ì´ë¯¸ì§€ë¥¼ Geminiì— ì „ì†¡ ê°€ëŠ¥í•œ Partë¡œ ë³€í™˜"""
        import io
        from google.genai import types
        
        # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
        img_byte_arr = io.BytesIO()
        image.save(img_byte_arr, format='PNG')
        img_bytes = img_byte_arr.getvalue()
        
        # genai.Partë¡œ ë³€í™˜
        return types.Part.from_bytes(
            data=img_bytes,
            mime_type="image/png"
        )
    
    async def _embed_text(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ì„ë² ë”©"""
        try:
            result = self.client.models.embed_content(
                model=self.embedding_model,
                content=text
            )
            return result.embedding.values
        except Exception as e:
            logger.error(f"Error embedding text: {e}")
            raise


vector_service = VectorService()
