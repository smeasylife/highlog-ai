"""ë¡œì»¬ PDF í…ŒìŠ¤íŠ¸ìš© API ì—”ë“œí¬ì¸íŠ¸ - S3 ì—†ì´ ì§ì ‘ PDF ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸"""
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from typing import Optional
import json
import asyncio
import io

from app.database import get_db
from app.models import StudentRecord, Question, QuestionSet
from app.services.vector_service import vector_service
from app.graphs.record_analysis import question_generation_graph, QuestionGenerationState
from app.schemas import SSEProgressEvent, GenerateQuestionsRequest
from app.schemas import InitializeInterviewRequest, SimpleChatRequest, InterviewChatResponse

import logging
import uuid

logger = logging.getLogger(__name__)

router = APIRouter()


async def send_progress(progress: int, queue: asyncio.Queue):
    """ì§„í–‰ë¥ ì„ íì— ì „ì†¡í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    await queue.put(progress)


def create_sse_event(progress: int, message: str = "") -> str:
    """SSE ì´ë²¤íŠ¸ ìƒì„± í—¬í¼ í•¨ìˆ˜"""
    event = SSEProgressEvent(
        type="processing",
        progress=progress,
        message=message
    )
    return f"data: {event.model_dump_json()}\n\n"


@router.post("/upload-pdf")
async def upload_local_pdf(
    file: UploadFile = File(...),
    user_id: int = 1,  # í…ŒìŠ¤íŠ¸ìš© ê¸°ë³¸ user_id
    title: str = "í…ŒìŠ¤íŠ¸ ìƒê¸°ë¶€",
    db: Session = Depends(get_db)
):
    """
    ë¡œì»¬ PDF íŒŒì¼ ì—…ë¡œë“œ í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸

    S3ë¥¼ ê±°ì¹˜ì§€ ì•Šê³  ì§ì ‘ PDFë¥¼ ì—…ë¡œë“œí•˜ì—¬ ë²¡í„°í™” í…ŒìŠ¤íŠ¸

    Note: target_school, target_major, interview_typeëŠ”
          ì§ˆë¬¸ ìƒì„± ì‹œ question_sets í…Œì´ë¸”ì— ì €ì¥ë©ë‹ˆë‹¤.
    """
    try:
        # 1. PDF íŒŒì¼ ì½ê¸°
        pdf_content = await file.read()
        pdf_bytes = io.BytesIO(pdf_content)

        logger.info(f"Received PDF file: {file.filename}, size: {len(pdf_content)} bytes")

        # 2. DBì— ìƒê¸°ë¶€ ì €ì¥ (S3 keyëŠ” ëŒ€ì‹  ë¡œì»¬ íŒŒì¼ëª… ì‚¬ìš©)
        record = StudentRecord(
            user_id=user_id,  # user_id ì¶”ê°€
            title=title,
            s3_key=f"local/{file.filename}",  # ë¡œì»¬ íŒŒì¼ì„ì„ í‘œì‹œ
            status="PENDING"
        )
        db.add(record)
        db.commit()
        db.refresh(record)

        # 3. ë²¡í„°í™” ì²˜ë¦¬
        return StreamingResponse(
            local_pdf_vectorization_stream(record, pdf_bytes, db),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )

    except Exception as e:
        logger.error(f"Error uploading local PDF: {e}")
        raise HTTPException(status_code=500, detail=f"PDF ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


async def local_pdf_vectorization_stream(record: StudentRecord, pdf_bytes: io.BytesIO, db: Session):
    """
    ë¡œì»¬ PDF ë²¡í„°í™” SSE ìŠ¤íŠ¸ë¦¼
    """
    try:
        # ì‹œì‘ ì´ë²¤íŠ¸ ì „ì†¡
        yield create_sse_event(0, "PDF ì—…ë¡œë“œ ì™„ë£Œ. ë²¡í„°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

        # ì§„í–‰ë¥  í ìƒì„±
        progress_queue = asyncio.Queue()

        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì‹¤í–‰
        vectorization_task = asyncio.create_task(
            _process_local_pdf_vectorization(
                record_id=record.id,
                pdf_bytes=pdf_bytes,
                db=db,
                progress_queue=progress_queue
            )
        )

        # ì§„í–‰ë¥  ì‹¤ì‹œê°„ ì „ì†¡
        while not vectorization_task.done() or not progress_queue.empty():
            try:
                progress = await asyncio.wait_for(progress_queue.get(), timeout=0.5)
                
                # ì§„í–‰ë¥ ì— ë”°ë¥¸ ë©”ì‹œì§€ ìƒì„±
                if progress < 20:
                    message = "PDF íŒŒì¼ ë¶„ì„ ì¤‘..."
                elif progress < 40:
                    message = "AIë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."
                elif progress < 70:
                    message = "ì¹´í…Œê³ ë¦¬ë³„ ì²­í‚¹ ì¤‘..."
                elif progress < 90:
                    message = "ë²¡í„° ì„ë² ë”© ë° ì €ì¥ ì¤‘..."
                elif progress < 100:
                    message = "ë§ˆë¬´ë¦¬ ì¤‘..."
                else:
                    message = "ì™„ë£Œ"
                
                yield create_sse_event(progress, message)
                
                # ë””ë²„ê¹…ìš© ë¡œê·¸
                logger.debug(f"ğŸ“Š SSE Progress: {progress}% - {message}")
                
            except asyncio.TimeoutError:
                continue

        # ì‘ì—… ê²°ê³¼ í™•ì¸
        success, message, total_chunks = await vectorization_task

        if not success:
            record.status = "FAILED"
            db.commit()

            error_event = SSEProgressEvent(
                type="error",
                progress=0,
                message=message
            )
            yield f"data: {error_event.model_dump_json()}\n\n"
            return

        # ì™„ë£Œ ì²˜ë¦¬
        record.status = "READY"
        db.commit()

        logger.info("")
        logger.info("âœ… PDF ì—…ë¡œë“œ ë° ë²¡í„°í™” ì™„ë£Œ")
        logger.info("=" * 60)

        complete_event = SSEProgressEvent(
            type="complete",
            progress=100,
            message=message
        )
        yield f"data: {complete_event.model_dump_json()}\n\n"

    except Exception as e:
        logger.error(f"Error in local PDF vectorization stream: {e}")

        try:
            record.status = "FAILED"
            db.commit()
        except:
            pass

        error_event = SSEProgressEvent(
            type="error",
            progress=0,
            questions=None
        )
        yield f"data: {error_event.model_dump_json()}\n\n"


async def _process_local_pdf_vectorization(
    record_id: int,
    pdf_bytes: io.BytesIO,
    db: Session,
    progress_queue: asyncio.Queue
):
    """
    ë¡œì»¬ PDF ë²¡í„°í™” ì²˜ë¦¬
    """
    # ì£¼ì˜: ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ì—ì„œëŠ” ìƒˆë¡œìš´ DB ì„¸ì…˜ ìƒì„± í•„ìš”
    from app.database import SessionLocal
    
    local_db = SessionLocal()
    try:
        logger.info(f"Processing local PDF vectorization for record {record_id}")

        # PDFë¥¼ ê·¸ëŒ€ë¡œ ë²¡í„°í™” ì„œë¹„ìŠ¤ë¡œ ì „ë‹¬
        await send_progress(10, progress_queue)

        logger.info("")
        logger.info("=" * 60)
        logger.info("ğŸ“„ ë¡œì»¬ PDF ë²¡í„°í™” ì‹œì‘")
        logger.info("=" * 60)

        # ë²¡í„°í™” (Gemini ì²­í‚¹ + ì„ë² ë”© + DB ì €ì¥) - PDF ì§ì ‘ ì „ë‹¬
        success, message, total_chunks = await vector_service.vectorize_pdf(
            pdf_bytes=pdf_bytes,  # PDF ë°”ì´íŠ¸ë¥¼ ì§ì ‘ ì „ë‹¬
            record_id=record_id,
            db=local_db,  # ë¡œì»¬ DB ì„¸ì…˜ ì‚¬ìš©
            progress_callback=lambda p: send_progress(p, progress_queue)
        )

        if not success:
            logger.error("âŒ ë²¡í„°í™” ì‹¤íŒ¨")
            raise Exception(message)

        logger.info("")
        logger.info("âœ… ë¡œì»¬ PDF ë²¡í„°í™” ì™„ë£Œ")
        logger.info("=" * 60)

        return True, message, total_chunks

    except Exception as e:
        logger.error(f"Error processing local PDF vectorization: {e}")

        try:
            record = local_db.query(StudentRecord).filter(
                StudentRecord.id == record_id
            ).first()
            if record:
                record.status = "FAILED"
                local_db.commit()
        except Exception as db_error:
            logger.error(f"Error updating record status: {db_error}")

        return False, str(e), 0
        
    finally:
        local_db.close()


@router.post("/{record_id}/generate-questions")
async def test_generate_questions(
    record_id: int,
    target_school: Optional[str] = "ì„œìš¸ëŒ€í•™êµ",
    target_major: Optional[str] = "ì»´í“¨í„°ê³µí•™ê³¼",
    interview_type: Optional[str] = "ì¢…í•©ì „í˜•",
    db: Session = Depends(get_db)
):
    """
    ì§ˆë¬¸ ìƒì„± í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸

    ë²¡í„°í™”ê°€ ì™„ë£Œëœ ìƒê¸°ë¶€ì— ëŒ€í•´ ì§ˆë¬¸ì„ ìƒì„±
    """
    try:
        # 1. ìƒê¸°ë¶€ ì¡°íšŒ
        record = db.query(StudentRecord).filter(
            StudentRecord.id == record_id
        ).first()

        if not record:
            raise HTTPException(status_code=404, detail="ìƒê¸°ë¶€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if record.status != "READY":
            raise HTTPException(
                status_code=400,
                detail=f"ë²¡í„°í™”ê°€ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ ìƒíƒœ: {record.status}"
            )

        # 2. ìš”ì²­ ê°ì²´ ìƒì„±
        request = GenerateQuestionsRequest(
            record_id=record_id,
            target_school=target_school,
            target_major=target_major,
            interview_type=interview_type
        )

        # 3. ì§ˆë¬¸ ìƒì„± ìŠ¤íŠ¸ë¦¼ ë°˜í™˜
        from app.api.records import question_generation_stream

        return StreamingResponse(
            question_generation_stream(record_id, request, db),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error generating test questions: {e}")
        raise HTTPException(status_code=500, detail="ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


@router.get("/records")
async def list_test_records(db: Session = Depends(get_db)):
    """
    ë“±ë¡ëœ ëª¨ë“  ìƒê¸°ë¶€ ëª©ë¡ ì¡°íšŒ (í…ŒìŠ¤íŠ¸ìš©)
    """
    try:
        records = db.query(StudentRecord).order_by(StudentRecord.id.desc()).all()

        result = [
            {
                "id": r.id,
                "title": r.title,
                "status": r.status,
                "created_at": r.created_at
            }
            for r in records
        ]

        return {"records": result, "total": len(result)}

    except Exception as e:
        logger.error(f"Error listing records: {e}")
        raise HTTPException(status_code=500, detail="ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


@router.get("/{record_id}/chunks")
async def get_record_chunks(record_id: int, db: Session = Depends(get_db)):
    """
    ìƒê¸°ë¶€ì˜ ë²¡í„°í™”ëœ ì²­í¬ ëª©ë¡ ì¡°íšŒ (í…ŒìŠ¤íŠ¸ìš©)
    """
    try:
        from app.models import RecordChunk

        chunks = db.query(RecordChunk).filter(
            RecordChunk.record_id == record_id
        ).order_by(RecordChunk.chunk_index).all()

        result = [
            {
                "id": c.id,
                "chunk_index": c.chunk_index,
                "category": c.category,
                "text": c.chunk_text[:200] + "..." if len(c.chunk_text) > 200 else c.chunk_text,
                "text_length": len(c.chunk_text)
            }
            for c in chunks
        ]

        return {"chunks": result, "total": len(result)}

    except Exception as e:
        logger.error(f"Error getting chunks: {e}")
        raise HTTPException(status_code=500, detail="ì²­í¬ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


@router.get("/{record_id}/questions")
async def get_record_questions(record_id: int, db: Session = Depends(get_db)):
    """
    ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡ ì¡°íšŒ (í…ŒìŠ¤íŠ¸ìš©)

    record_idì— ì†í•œ ëª¨ë“  question_setsì˜ ì§ˆë¬¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        from app.models import QuestionSet

        # í•´ë‹¹ recordì˜ ëª¨ë“  question_sets ì¡°íšŒ
        question_sets = db.query(QuestionSet).filter(
            QuestionSet.record_id == record_id
        ).all()

        if not question_sets:
            return {"questions": [], "total": 0, "message": "ì§ˆë¬¸ ì„¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì§ˆë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”."}

        # ëª¨ë“  ì„¸íŠ¸ì˜ ì§ˆë¬¸ ì¡°íšŒ
        all_questions = []
        for qset in question_sets:
            questions = db.query(Question).filter(
                Question.set_id == qset.id
            ).order_by(Question.category).all()

            for q in questions:
                all_questions.append({
                    "id": q.id,
                    "set_id": q.set_id,
                    "question_set_info": {
                        "id": qset.id,
                        "target_school": qset.target_school,
                        "target_major": qset.target_major,
                        "interview_type": qset.interview_type,
                        "title": qset.title
                    },
                    "category": q.category,
                    "content": q.content,
                    "difficulty": q.difficulty,
                    "model_answer": q.model_answer
                })

        return {
            "questions": all_questions,
            "total": len(all_questions),
            "question_sets_count": len(question_sets)
        }

    except Exception as e:
        logger.error(f"Error getting questions: {e}")
        raise HTTPException(status_code=500, detail="ì§ˆë¬¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")


# ==================== ë©´ì ‘ í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸ (ì¸ì¦ ì—†ìŒ) ====================

@router.post("/interview/initialize", response_model=InterviewChatResponse)
async def test_initialize_interview(request: InitializeInterviewRequest):
    """
    ë©´ì ‘ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸ (JWT ì¸ì¦ ì—†ìŒ)

    interview.pyì˜ initialize_interviewì™€ ë™ì¼í•œ ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        from app.graphs.interview_graph import interview_graph

        logger.info(f"[TEST] Initializing interview for record {request.record_id}")

        # ê³ ìœ  thread_id ìƒì„±
        thread_id = f"test_interview_{request.record_id}_{uuid.uuid4().hex[:8]}"
        logger.info(f"[TEST] Generated thread_id: {thread_id}")

        # InterviewGraph ì´ˆê¸°í™” ì²˜ë¦¬
        result = await interview_graph.initialize_interview(
            record_id=request.record_id,
            difficulty=request.difficulty,
            first_answer=request.first_answer,
            response_time=request.response_time,
            thread_id=thread_id
        )

        # ì‹¤ì‹œê°„ ë¶„ì„ ë°ì´í„° ì¶”ì¶œ
        analysis = None
        if result['updated_state'].get('answer_metadata'):
            last_metadata = result['updated_state']['answer_metadata'][-1]
            analysis = last_metadata.get('evaluation')

        return InterviewChatResponse(
            next_question=result['next_question'],
            analysis=analysis,
            is_finished=result['is_finished'],
            thread_id=thread_id
        )

    except Exception as e:
        logger.error(f"[TEST] Error in initialize_interview: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/interview/chat/text/{thread_id}", response_model=InterviewChatResponse)
async def test_chat_text(
    thread_id: str,
    request: SimpleChatRequest
):
    """
    í…ìŠ¤íŠ¸ ê¸°ë°˜ ë©´ì ‘ í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸ (JWT ì¸ì¦ ì—†ìŒ)

    interview.pyì˜ chat_textì™€ ë™ì¼í•œ ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        from app.graphs.interview_graph import interview_graph
        from typing import Dict, Any

        logger.info(f"[TEST] Text chat request for thread_id: {thread_id}")

        # Checkpointerì—ì„œ ìƒíƒœ ì¡°íšŒí•˜ì—¬ ì²˜ë¦¬
        result = await _test_process_chat_with_checkpoint(
            user_answer=request.answer,
            response_time=request.response_time,
            thread_id=thread_id
        )

        # ì‹¤ì‹œê°„ ë¶„ì„ ë°ì´í„° ì¶”ì¶œ
        analysis = None
        if result['updated_state'].get('answer_metadata'):
            last_metadata = result['updated_state']['answer_metadata'][-1]
            analysis = last_metadata.get('evaluation')

        return InterviewChatResponse(
            next_question=result['next_question'],
            analysis=analysis,
            is_finished=result['is_finished']
        )

    except Exception as e:
        logger.error(f"[TEST] Error in chat_text: {e}")
        raise HTTPException(status_code=500, detail=str(e))


async def _test_process_chat_with_checkpoint(
    user_answer: str,
    response_time: int,
    thread_id: str
) -> Dict[str, Any]:
    """
    Checkpointerì—ì„œ ìƒíƒœë¥¼ ì¡°íšŒí•˜ì—¬ ë‹µë³€ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸ìš©)

    interview.pyì˜ _process_chat_with_checkpointì™€ ë™ì¼í•œ ë¡œì§ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    try:
        from app.graphs.interview_graph import interview_graph

        # 1. Checkpointerì—ì„œ í˜„ì¬ ìƒíƒœ ì¡°íšŒ
        current_state = await interview_graph.get_state(thread_id)

        # 2. ìƒíƒœì—ì„œ record_id ì¶”ì¶œ
        record_id = current_state.get('record_id')

        # 3. InterviewGraph ì²˜ë¦¬
        result = await interview_graph.process_answer(
            state=current_state,
            user_answer=user_answer,
            response_time=response_time,
            record_id=record_id,
            thread_id=thread_id
        )

        return result

    except Exception as e:
        logger.error(f"[TEST] Error processing chat with checkpoint: {e}")
        raise

